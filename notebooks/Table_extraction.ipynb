{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "id": "AuWc9SUlcgO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "3GzHF8plc29n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su0IaAGjSYM7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz\n",
        "import pdfplumber  # For table extraction\n",
        "import pandas as pd\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "xadd0_IidxJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your-hf-token' with your actual Hugging Face API token\n",
        "os.environ[\"HF_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "5St5AVZ_dyr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Login using the token\n",
        "login(token=os.environ[\"HF_TOKEN\"])\n",
        "\n",
        "# Initialize the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-large\", tokenizer=\"t5-large\")"
      ],
      "metadata": {
        "id": "3_KuIszCdyoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_page_and_table_summary(page_text, table):\n",
        "    \"\"\"\n",
        "    Generate a prompt for summarization by combining page text with table information.\n",
        "    \"\"\"\n",
        "    prompt = \"Summarize the following content along with the table:\\n\\n\"\n",
        "    prompt += page_text[:500] + \"\\n\"  # Include the first 500 characters of the page\n",
        "    prompt += \"Table:\\n\"\n",
        "\n",
        "    for row in table:\n",
        "        row_text = \" | \".join([str(cell) for cell in row])\n",
        "        prompt += row_text + \"\\n\"\n",
        "\n",
        "    return prompt.strip()"
      ],
      "metadata": {
        "id": "a0HHKHhhgJg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "'''def get_prompt_table_summarization(table):\n",
        "    \"\"\"\n",
        "    Generate a prompt for table summarization.\n",
        "    \"\"\"\n",
        "    prompt = \"Summarize the following table:\\n\"\n",
        "\n",
        "    # Convert the table rows to text\n",
        "    for row in table:\n",
        "        if row:  # Ensure the row is not empty\n",
        "            row_text = \" | \".join([str(cell) for cell in row])  # Format each row with '|' separator\n",
        "            prompt += row_text + \"\\n\"\n",
        "\n",
        "    return prompt.strip()  # Remove any trailing spaces/newlines'''\n",
        "\n",
        "def generate_text(prompt):\n",
        "    \"\"\"\n",
        "    Generate a summary of the table using the LLM model.\n",
        "    \"\"\"\n",
        "    if not prompt:  # Check if prompt is empty\n",
        "        print(\"Empty prompt, skipping summarization.\")\n",
        "        return \"Empty prompt\"\n",
        "\n",
        "    try:\n",
        "        input_length = len(prompt.split())\n",
        "        print(f\"Input Length: {input_length}\")\n",
        "\n",
        "        # Set max_length to encourage concise summaries\n",
        "        max_length = min(150, input_length) if input_length > 1 else 5\n",
        "\n",
        "        # Summarize the prompt using the LLM summarization model\n",
        "        summary = summarizer(prompt, max_length=max_length, min_length=5, do_sample=False)\n",
        "        #summary = summarizer(prompt, max_length=150, min_length=30, temperature=0.7, top_k=50)[0]['summary_text']\n",
        "\n",
        "        print(f\"Summary: {summary}\")\n",
        "\n",
        "        return summary[0]['summary_text'] if summary else \"No summary generated\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model inference: {str(e)}\")\n",
        "        return \"Error generating summary\"\n",
        "\n",
        "def extract_table_data_from_pdfs(pdf_directory):\n",
        "    data = []\n",
        "\n",
        "    # List all PDF files in the specified directory\n",
        "    pdf_files = [f for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
        "\n",
        "    # Process each PDF file\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(pdf_directory, pdf_file)\n",
        "        print(f\"Processing {pdf_file}...\")\n",
        "\n",
        "        # Open PDF using pdfplumber for table extraction\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for i in range(len(pdf.pages)):\n",
        "                try:\n",
        "                    page_plumber = pdf.pages[i]\n",
        "                    tables = page_plumber.extract_tables()\n",
        "\n",
        "                    # Extract the page text using fitz (PyMuPDF)\n",
        "                    pdf_fitz = fitz.open(pdf_path)\n",
        "                    page_text = pdf_fitz[i].get_text()\n",
        "\n",
        "                    if tables:\n",
        "                        for table in tables:\n",
        "                            if len(table) > 2:  # Filter out very small tables\n",
        "                                # Generate a prompt that includes both page text and table data\n",
        "                                prompt = get_page_and_table_summary(page_text, table)\n",
        "                                if prompt:  # Proceed only if the prompt is not empty\n",
        "                                    table_summary = generate_text(prompt)\n",
        "\n",
        "                                    # Collecting the data: PDF name, page number, and table summary\n",
        "                                    data.append({\n",
        "                                        \"pdf_name\": pdf_file,\n",
        "                                        \"page_number\": i + 1,\n",
        "                                        \"table_summary\": table_summary\n",
        "                                    })\n",
        "                                    print(f\"Table summarized on page {i + 1} of {pdf_file}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error on page {i + 1} of {pdf_file}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    # Convert data to DataFrame and save to CSV\n",
        "    df = pd.DataFrame(data)\n",
        "    output_csv_path = os.path.join(pdf_directory, \"extracted_table_summaries.csv\")\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Data saved to {output_csv_path}\")\n",
        "\n",
        "# Example usage\n",
        "pdf_directory_path = \"/content/drive/MyDrive/ASAPP/papers\"  # Change this to your PDF directory\n",
        "extract_table_data_from_pdfs(pdf_directory_path)\n"
      ],
      "metadata": {
        "id": "i4yD-LyYhCBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/ASAPP/dummy/extracted_table_summaries.csv\")"
      ],
      "metadata": {
        "id": "G4dTobb3eDEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "v7vQGa7EfDMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "ywARtUh-kKYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OcUBDWrvV7Ve"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}